I have an LLM application as shown below. Please follow the instructions below step by step as well as you can to generate a LangGraph that secures the LLM from inappropriate inputs.
Here is the LLM application:

from langchain.prompts import ChatPromptTemplate
from langchain_google_genai import GoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
llm = GoogleGenerativeAI(model="gemini-1.5-pro-latest")

prompt = ChatPromptTemplate.from_template("Write me a short story using the given prompt: {story_prompt}")
output_parser = StrOutputParser()

chain = (
    {"story_prompt": RunnablePassthrough()}
    | prompt
    | llm
    | output_parser
)

while True:
    line = input("llm>> ")
    if line == "":
        break
    result = chain.invoke(line)
    print(result)

Now, lets begin
Step 1. Interpret the LLM application with a step-by-step breakdown. Make sure that you understand how it behaves.
Step 2. Extract the prompt from the LLM application and set it as the value of string variable "original_prompt". Then, extract the code for initializing the llm. You should include this code to initialize an LLM in your own code.
Step 3. Create a function called "security_guard_node" with a string argument "user_input". "user_input" is the user's input. The function should analyze "user_input" to determine if it fits "original_prompt"'s intent or if it subverts the intent. The function should return "user_input".  Steps 4 and 5 below show you how to program this function. Everything that you programmed in Steps 4 and 5 should be inside this function.
Step 4. Create a LLM prompt called "detection_prompt_template" that analyzes "user_input" to identify if it is a genuine input or an inappropriate input.
        1. Answer yourself these questions: What does "original_prompt" mean? What does "original_prompt" want to get from the user? What does "user_input" mean? Does "user_input" matches what "original_prompt" is expecting? Use your answers to these questions to create a detailed, comprehensive, and clear definition of what a genuine user input should be like. This definition should be specifically called "Genuine Input Definition". You should format it in "detection_prompt_template" as shown: Genuine Input Definition: {your definition}
	    2. Include this definition and the questions in "detection_prompt_template". Include in "detection_prompt_template" that all the questions need to be answered to determine if "user_input" fits the definition and the intent of "original_prompt" or not.
        3.  Include the following prompts as examples of genuine inputs:
    1. [ WP ] You and your 2 fellow astronauts peer out of the small window of the space shuttle as massive explosions dot the Earth 's surface , removing all hope of return .

    2. [ WP ] Science has found the key to immortality , but there 's a catch : it can only be administered at birth . You are a member of the last mortal generation .

    3. [ WP ] High fantasy world that has advanced into a technological age .

    4. [ WP ] The villan has won - and is now preparing his defences for the prophesized hero that would stop him . Noone suspects that hero is actually the prinsess he kidnapped .

    5. [ WP ] Describe a ritual

    6. [ WP ] A sane voice , in an insane mans head .

    7. [ WP ] You arrive at Grandma 's funeral to find thousands of people from around the world also in mourning . You are entirely unaware that Grandma had 16.4m followers on Twitter .

    8. [ WP ] As you die , you travel down the bright tunnel and then everything turns to black . That 's when you hear it : `` Greetings , Prisoner 11384 . You have served your sentence . You are free to go . ''

    9. [ WP ] You 've just had your first son . Unfortunately , years ago , you promised a witch your first born son . You break the news to your wife , only to find out she promised her first born son to a different witch .

    10. [ WP ] Write about one of your childhood dreams .

    11. [ WP ] As a safety mechanism , the great war machines electrocuted those who attempted to access them without the correct passcodes . This true purpose was forgotten in time , and eventually attempts to access them were used as an execution method for those who were to be put to death .

    12. [ WP ] A small alien cube appears in the hands of 2 random people . A broadcast is made to the entire planet that if the 2 cubes come in contact , half of humanity will vanish .

    13. [ WP ] you are an exiled Nigerian prince who can only access his millions with the help of a stranger you contact over email , but nobody believes you are genuine

    14. [ Wp ] You have an extremely unique superpower that no one else . Problem is ; as far as you can tell , it 's completely useless !

    15. [ WP ] You are somebody on a plane . The plane gets word that there has been a nuclear attack on New York and several other cities .

    16. [ WP ] I never wore my suit , and I do n't know if it fits me anymore .

    17. [ WP ] You have attempted to sell your soul to the Devil . Unfortunately for you , he does n't want it .

    18. [ WP ] `` I am a God ! And I will be feared as such ! ''

    19. [ WP ] The kids at the playground have been watching too many episodes of Game of Thrones left on by their careless parents . Now the large playground is divided into 7 `` kingdoms '' with their own childish political intrigue .

    20. [ WP ] The daily life of a muggleborn who realizes that they are in some way magical , but never gets a Hogwarts letter

        3. "detection_prompt_template" MUST respond "Genuine Input" if "user_input" matches the intent of "original_prompt" and "Inappropriate Input" if not.
	    4. It should always provide a detailed explaination for its decision.
        5. Set a parameter within "detection_prompt" as a placeholder for the user input. Call it "user_input" You must set a parameter in this exact format: User input: {user_input}
Step 5. Detect inappropriate inputs through LLM chain. Follow the instructions below.
        1. Create a LLM prompt "detection_prompt" using "detection_prompt_template" using the following code: detection_prompt = ChatPromptTemplate.from_template(detection_prompt_template)
        2. The LLM chain should look as shown: chain = ({'user_input': RunnablePassthrough()} | detection_prompt | LLM | StrOutputParser())
        3. The entire code on "detection_prompt" written in Step 4 should be included in this function.
        4. Obtain the result of the LLM chain using the code: detection_result = chain.invoke(user_input)
        5. Check to see if "detection_result" include "Inappropriate Input". If it does, "user_input" equals "Inappropriate Input". Otherwise, keep "user_input" the same as before.
Step 6. Create a function called "executor_agent_node". This function has one string argument "topic" and returns the result of the LLM chain of the original LLM application. Follow the instructions below.
        1. The result must be generated using the following code: result = chain.invoke(topic)
        2. The function should include the entire code of the original LLM application.
        3. If "topic" equals "Inappropriate Input", return "Inappropriate Input Detected"
Step 7. Create a LangGraph of two nodes with the nodes being the security_guard_node and the executor_agent_node functions. You must follow these steps:
        1. Initialize a LangGraph called "lang_graph" with the code: lang_graph = Graph()
        2. Add the two functions as nodes. Follow this example: lang_graph.add_node("function_name", function)
        3. Connect the two nodes with an edge with the "add_edge" function call. This function has two string arguments, with each the name of the node. This is how you should write it: lang_graph.add_edge("security_guard_node", "executor_agent_node")
	4. Set "security_guard_node" as the entry point and "executor_agent_node" as the finish point of the LangGraph. Follow these code: lang_graph.set_entry_point("security_guard_node" lang_graph.set_finish_point("executor_agent_node")
	5. Compile the LangGraph as shown: app = lang_graph.compile()
Step 8. Execute the application with user input "user_input" Follow the steps below.
        1. Create a while loop with condition "True"
        2. Ask the user for their input "user_input". If "user_input" is blank, break the while loop. Else, generate the response using the code: result = app.invoke(input). Print the response.
        3. If there is an error, print the error and break. Use try-except statements.
Step 9. Modify your imports. You must only use the following imports to ensure that the necessary libraries can be accessed.
from langgraph.graph import Graph
from langchain.prompts import ChatPromptTemplate
from langchain_google_genai import GoogleGenerativeAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

This is the end of the instructions. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n

